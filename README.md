# Advanced 3D Object Tracking and Pose Estimation for Dynamic Environments

This project focuses on creating a robust framework for 3D object tracking and pose estimation in dynamic environments. By utilizing advanced contour analysis, pose estimation techniques, and real-time visualization, the system delivers accurate object tracking and orientation estimation for applications in robotics, autonomous navigation, and augmented reality.

---

## Features
- **3D Object Tracking**: Efficiently tracks objects in dynamic environments, handling challenges like occlusion, motion blur, and varying lighting.
- **Pose Estimation**: Calculates rotation and translation vectors to estimate the precise orientation and position of objects in 3D space.
- **Real-Time Processing**: Achieves real-time performance with processing speeds of up to 45 FPS.
- **Visual Effects**: Implements 3D wireframe rendering, particle systems, and glow effects for enhanced augmented reality visualization.
- **Comparison with YOLO**: Demonstrates superior speed and efficiency of traditional methods compared to deep learning models like YOLO in resource-constrained scenarios.

---

## Technologies Used
- **Languages**: Python
- **Libraries**: OpenCV, NumPy, SciPy
- **Algorithms**: Contour Analysis, Perspective-n-Point (PnP), Edge Detection, Pyramid Detection
- **Visualization**: 3D Wireframes, Particle Systems, Real-time Rendering

---

## Dataset
The project utilizes synthetic and real-world datasets, including:
- Video streams with objects exhibiting dynamic motion
- Frames containing varying lighting, occlusions, and motion blur

# Results
- Achieved 90% accuracy in controlled environments.
- Real-time performance at 45 FPS with minimal computational resources.
- Visualized 3D wireframes and particle systems for enhanced augmented reality effects.

# Contributors
- Tejas Mohandas Patil
- Shashank A Bhat
- Abhijith D Pai
